{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ads369/Ads_2s/blob/main/14_2_%D0%9F%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85_%D0%B4%D0%BB%D1%8F_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F_chatGPT_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D0%BE%D0%BC_Search_Ask_(%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Навигация по уроку**\n",
        "\n",
        "1. [Telegram бот c ChatGPT на борту. Знакомство с  ChatGPT](https://colab.research.google.com/drive/1tqXt0XNstMb2TeJ8Za9S2xQA6ipjyMPk)\n",
        "2. Подготовка данных для обучения chatGPT методом Search-Ask (Практика)\n",
        "3. [Домашняя работа](https://colab.research.google.com/drive/13zTaGNA9cr9SjaYFzpDPp-72i8SQFqrp)"
      ],
      "metadata": {
        "id": "wYEpuSjRJ6jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перед вами практическая часть урока. Проанализируйте данный Блокнот и попробуйте самостоятельно сформировать базу знаний (файл `csv`) по интересующей вас теме. В домашней работе, вы будете использовать ваш файл базы знаний, чтобы создать телеграм-бот, который отвечает на вопросы по вашей базе знаний. Мы настоятельно рекомендуем ознакомиться с [домашним заданием](https://colab.research.google.com/drive/13zTaGNA9cr9SjaYFzpDPp-72i8SQFqrp) перед выбором тематики для вашей базы знаний. Ваша база знаний может быть как результатом парсинга Википедии, так и любого другого ресурса, включая выгрузку из мессенджеров, zoom-конференций, нормативной базы компании."
      ],
      "metadata": {
        "id": "Q-ykx-XIHO70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "И так вспомним алгоритм Search-Ask, а точнее его первый пункт о подготовке поисковых данных:\n",
        "* Сбор: загружаем документы;\n",
        "* Фрагментация: документы разбиваются на короткие, в основном автономные разделы для токенизации;\n",
        "* Токенизация или вычисление эмбендингов: каждый раздел преобразуется в последовательность токенов с помощью OpenAI API;\n",
        "* Хранилище: последовательности токенов сохраняются.\n"
      ],
      "metadata": {
        "id": "y49QkHP8P25I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сбор данных и фрагментация"
      ],
      "metadata": {
        "id": "RlhFAOYfhI5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для сбора и подготовки данных нам необходимо:\n",
        "* Собрать все заголовки статей заданной категории статей Википедии, заходя на первый уровень вложенности статей.\n",
        "* Разделить каждую статью на разделы (секции) и подразделы. Отбросить менее релевантные разделы, такие как внешние ссылки и сноски.\n",
        "* Очистить текст, удалив теги ссылок, пробелы и очень короткие секции (разделы).\n",
        "* Добавить заголовки и подзаголовки к тексту каждого раздела, чтобы помочь chatGPT понять контекст."
      ],
      "metadata": {
        "id": "1P-w02hASPVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сбор заголовков статей из категории"
      ],
      "metadata": {
        "id": "52qZgnP0SoCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Отключим предупреждения в колабе. Будет меньше лишней информации в выводе\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmFaPCEN6FWl",
        "outputId": "8e5c935e-6291-4321-b914-51d91b1bc787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vj319smw67_",
        "outputId": "a86892a6-10e3-429f-f657-245947a509d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: mwclient in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.10/dist-packages (0.6.6)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from mwclient) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mwclient) (1.16.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->mwclient) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai mwclient mwparserfromhell tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import mwclient  # библиотека для работы с MediaWiki API для загрузки примеров статей Википедии\n",
        "import mwparserfromhell  # Парсер для MediaWiki\n",
        "import openai  # будем использовать для токинизации\n",
        "import pandas as pd  # В DataFrame будем хранить базу знаний и результат токинизации базы знаний\n",
        "import re  # для вырезания ссылок <ref> из статей Википедии\n",
        "import tiktoken  # для подсчета токенов"
      ],
      "metadata": {
        "id": "gsD_cLZsxehi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# поиск страниц Википедии о зимних Олимпийских играх 2022 года\n",
        "\n",
        "# Задаем категорию и англоязычную версию Википедии для поиска\n",
        "CATEGORY_TITLE = \"Category:2022 Winter Olympics\"\n",
        "WIKI_SITE = \"en.wikipedia.org\"\n",
        "\n",
        "# Соберем заголовки всех статей\n",
        "def titles_from_category(\n",
        "    category: mwclient.listing.Category, # Задаем типизированный параметр категории статей\n",
        "    max_depth: int # Определяем глубину вложения статей\n",
        ") -> set[str]:\n",
        "    \"\"\"Возвращает набор заголовков страниц в данной категории Википедии и ее подкатегориях.\"\"\"\n",
        "    titles = set() # Используем множество для хранения заголовков статей\n",
        "    for cm in category.members(): # Перебираем вложенные объекты категории\n",
        "        if type(cm) == mwclient.page.Page: # Если объект является страницей\n",
        "            titles.add(cm.name) # в хранилище заголовков добавляем имя страницы\n",
        "        elif isinstance(cm, mwclient.listing.Category) and max_depth > 0: # Если объект является категорией и глубина вложения не достигла максимальной\n",
        "            deeper_titles = titles_from_category(cm, max_depth=max_depth - 1) # вызываем рекурсивно функцию для подкатегории\n",
        "            titles.update(deeper_titles) # добавление в множество элементов из другого множества\n",
        "    return titles\n",
        "\n",
        "# Инициализация объекта MediaWiki\n",
        "# WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "site = mwclient.Site(WIKI_SITE)\n",
        "\n",
        "# Загрузка раздела заданной категории\n",
        "category_page = site.pages[CATEGORY_TITLE]\n",
        "# Получение множества всех заголовков категории с вложенностью на один уровень\n",
        "titles = titles_from_category(category_page, max_depth=1)\n",
        "\n",
        "\n",
        "print(f\"Создано {len(titles)} заголовков статей в категории {CATEGORY_TITLE}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYPCIHcxxm5F",
        "outputId": "632eaa99-ad6d-4fc1-c605-8bb4825cd6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Создано 732 заголовков статей в категории Category:2022 Winter Olympics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Извлечение секций из документов"
      ],
      "metadata": {
        "id": "NnZQNAmWRZtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определим секции в документах, которые менее релевантны и их можно отбросить:\n",
        "\n"
      ],
      "metadata": {
        "id": "8G10Fuk-QtIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем секции, которые будут отброшены при парсинге статей\n",
        "SECTIONS_TO_IGNORE = [\n",
        "    \"See also\",\n",
        "    \"References\",\n",
        "    \"External links\",\n",
        "    \"Further reading\",\n",
        "    \"Footnotes\",\n",
        "    \"Bibliography\",\n",
        "    \"Sources\",\n",
        "    \"Citations\",\n",
        "    \"Literature\",\n",
        "    \"Footnotes\",\n",
        "    \"Notes and references\",\n",
        "    \"Photo gallery\",\n",
        "    \"Works cited\",\n",
        "    \"Photos\",\n",
        "    \"Gallery\",\n",
        "    \"Notes\",\n",
        "    \"References and sources\",\n",
        "    \"References and notes\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "8TVbIHz9RSGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция возвращает список всех вложенных секций для заданной секции страницы Википедии\n",
        "\n",
        "def all_subsections_from_section(\n",
        "    section: mwparserfromhell.wikicode.Wikicode, # текущая секция\n",
        "    parent_titles: list[str], # Заголовки родителя\n",
        "    sections_to_ignore: set[str], # Секции, которые необходимо проигнорировать\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из раздела Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Извлекаем заголовки текущей секции\n",
        "    headings = [str(h) for h in section.filter_headings()]\n",
        "    title = headings[0]\n",
        "    # Заголовки Википедии имеют вид: \"== Heading ==\"\n",
        "\n",
        "    if title.strip(\"=\" + \" \") in sections_to_ignore:\n",
        "        # Если заголовок секции в списке для игнора, то пропускаем его\n",
        "        return []\n",
        "\n",
        "    # Объединим заголовки и подзаголовки, чтобы сохранить контекст для chatGPT\n",
        "    titles = parent_titles + [title]\n",
        "\n",
        "    # Преобразуем wikicode секции в строку\n",
        "    full_text = str(section)\n",
        "\n",
        "    # Выделяем текст секции без заголовка\n",
        "    section_text = full_text.split(title)[1]\n",
        "    if len(headings) == 1:\n",
        "        # Если один заголовок, то формируем результирующий список\n",
        "        return [(titles, section_text)]\n",
        "    else:\n",
        "        first_subtitle = headings[1]\n",
        "        section_text = section_text.split(first_subtitle)[0]\n",
        "        # Формируем результирующий список из текста до первого подзаголовка\n",
        "        results = [(titles, section_text)]\n",
        "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
        "            results.extend(\n",
        "                # Вызываем функцию получения вложенных секций для заданной секции\n",
        "                all_subsections_from_section(subsection, titles, sections_to_ignore)\n",
        "                )  # Объединяем результирующие списки данной функции и вызываемой\n",
        "        return results\n",
        "\n",
        "# Функция возвращает список всех секций страницы, за исключением тех, которые отбрасываем\n",
        "def all_subsections_from_title(\n",
        "    title: str, # Заголовок статьи Википедии, которую парсим\n",
        "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE, # Секции, которые игнорируем\n",
        "    site_name: str = WIKI_SITE, # Ссылка на сайт википедии\n",
        ") -> list[tuple[list[str], str]]:\n",
        "    \"\"\"\n",
        "    Из заголовка страницы Википедии возвращает список всех вложенных секций.\n",
        "    Каждый подраздел представляет собой кортеж, где:\n",
        "      - первый элемент представляет собой список родительских секций, начиная с заголовка страницы\n",
        "      - второй элемент представляет собой текст секции\n",
        "    \"\"\"\n",
        "\n",
        "    # Инициализация объекта MediaWiki\n",
        "    # WIKI_SITE ссылается на англоязычную часть Википедии\n",
        "    site = mwclient.Site(site_name)\n",
        "\n",
        "    # Запрашиваем страницу по заголовку\n",
        "    page = site.pages[title]\n",
        "\n",
        "    # Получаем текстовое представление страницы\n",
        "    text = page.text()\n",
        "\n",
        "    # Удобный парсер для MediaWiki\n",
        "    parsed_text = mwparserfromhell.parse(text)\n",
        "    # Извлекаем заголовки\n",
        "    headings = [str(h) for h in parsed_text.filter_headings()]\n",
        "    if headings: # Если заголовки найдены\n",
        "        # В качестве резюме берем текст до первого заголовка\n",
        "        summary_text = str(parsed_text).split(headings[0])[0]\n",
        "    else:\n",
        "        # Если нет заголовков, то весь текст считаем резюме\n",
        "        summary_text = str(parsed_text)\n",
        "    results = [([title], summary_text)] # Добавляем резюме в результирующий список\n",
        "    for subsection in parsed_text.get_sections(levels=[2]): # Извлекаем секции 2-го уровня\n",
        "        results.extend(\n",
        "            # Вызываем функцию получения вложенных секций для заданной секции\n",
        "            all_subsections_from_section(subsection, [title], sections_to_ignore)\n",
        "        ) # Объединяем результирующие списки данной функции и вызываемой\n",
        "    return results"
      ],
      "metadata": {
        "id": "fVL7yHeex2nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбивка статей на секции\n",
        "# придется немного подождать, так как на парсинг 100 статей требуется около минуты\n",
        "wikipedia_sections = []\n",
        "for title in titles:\n",
        "    wikipedia_sections.extend(all_subsections_from_title(title))\n",
        "print(f\"Найдено {len(wikipedia_sections)} секций на {len(titles)} страницах\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbUDCg3bx_h2",
        "outputId": "f696eec0-3066-409a-8255-7b35b7324016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено 5795 секций на 732 страницах\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Очистка текста (теги ссылок, пробелы и короткие секции)"
      ],
      "metadata": {
        "id": "4up_BckM3oc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистка текста секции от ссылок <ref>xyz</ref>, начальных и конечных пробелов\n",
        "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
        "    titles, text = section\n",
        "    # Удаляем ссылки\n",
        "    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
        "    # Удаляем пробелы вначале и конце\n",
        "    text = text.strip()\n",
        "    return (titles, text)\n",
        "\n",
        "# Применим функцию очистки ко всем секциям с помощью генератора списков\n",
        "wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n",
        "\n",
        "# Отфильтруем короткие и пустые секции\n",
        "def keep_section(section: tuple[list[str], str]) -> bool:\n",
        "    \"\"\"Возвращает значение True, если раздел должен быть сохранен, в противном случае значение False.\"\"\"\n",
        "    titles, text = section\n",
        "    # Фильтруем по произвольной длине, можно выбрать и другое значение\n",
        "    if len(text) < 16:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "original_num_sections = len(wikipedia_sections)\n",
        "wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
        "print(f\"Отфильтровано {original_num_sections-len(wikipedia_sections)} секций, осталось {len(wikipedia_sections)} секций.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdxev4SjyDwr",
        "outputId": "866b27f7-66ac-4615-fb2e-880cd31b1c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отфильтровано 531 секций, осталось 5264 секций.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для наглядности выведем 5 секций, заголовок и текст (50 первых символов) каждой секции"
      ],
      "metadata": {
        "id": "yDjkQXDj5M_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ws in wikipedia_sections[:5]:\n",
        "    print(ws[0])\n",
        "    display(ws[1][:50] + \"...\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "m2kAKocO5N7X",
        "outputId": "423888ea-0ed3-41f9-c118-e0661c062bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Belgium at the 2022 Winter Olympics']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Infobox country at games\\n|NOC = BEL\\n|NOCname = [...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Belgium at the 2022 Winter Olympics', '==Medalists==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{further|2022 Winter Olympics medal table|List of...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Belgium at the 2022 Winter Olympics', '==Competitors==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The following is a list of the number of competito...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Belgium at the 2022 Winter Olympics', '==Alpine skiing==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{main article|Alpine skiing at the 2022 Winter Ol...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "['Belgium at the 2022 Winter Olympics', '== Biathlon ==']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'{{Main|Biathlon at the 2022 Winter Olympics|Biathl...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Фрагментация документов"
      ],
      "metadata": {
        "id": "97t-_GMQLCZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поскольку chatGPT может одновременно считывать только ограниченный объем токенов, нам необходимо разделить каждый документ на фрагменты (части).\n",
        "\n",
        "Далее мы рекурсивно разделим длинные разделы на более мелкие. Идеального рецепта разделения текста на разделы не существует.\n",
        "\n",
        "Однако, можно сделать следующие предположения:\n",
        "\n",
        "* Более длинные разделы могут быть лучше для вопросов, требующих большего контекста.\n",
        "* Более длинные разделы могут быть хуже для поиска, поскольку в них может быть больше запутанных тем.\n",
        "* Более короткие разделы лучше подходят для снижения затрат, которые пропорциональны количеству токенов.\n",
        "* Более короткие разделы позволяют извлекать больше разделов для запроса, что может помочь с полнотой данных.\n",
        "* Перекрывающиеся разделы могут помочь предотвратить обрезание ответов по смыслу границами разделов.\n",
        "\n",
        "Учитывая все выше сказанное, мы будем использовать простой подход и ограничим количество разделов до 1600 токенов в каждом, рекурсивно сокращая вдвое любые слишком длинные разделы. Во избежание сокращения в середине полезных предложений, мы будем разделять секции на части по границам абзацев."
      ],
      "metadata": {
        "id": "pIT1i3yfLDHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n",
        "\n",
        "# Функция подсчета токенов\n",
        "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
        "    \"\"\"Возвращает число токенов в строке.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# Функция разделения строк\n",
        "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
        "    \"\"\"Разделяет строку надвое с помощью разделителя (delimiter), пытаясь сбалансировать токены с каждой стороны.\"\"\"\n",
        "\n",
        "    # Делим строку на части по разделителю, по умолчанию \\n - перенос строки\n",
        "    chunks = string.split(delimiter)\n",
        "    if len(chunks) == 1:\n",
        "        return [string, \"\"]  # разделитель не найден\n",
        "    elif len(chunks) == 2:\n",
        "        return chunks  # нет необходимости искать промежуточную точку\n",
        "    else:\n",
        "        # Считаем токены\n",
        "        total_tokens = num_tokens(string)\n",
        "        halfway = total_tokens // 2\n",
        "        # Предварительное разделение по середине числа токенов\n",
        "        best_diff = halfway\n",
        "        # В цикле ищем какой из разделителей, будет ближе всего к best_diff\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            left = delimiter.join(chunks[: i + 1])\n",
        "            left_tokens = num_tokens(left)\n",
        "            diff = abs(halfway - left_tokens)\n",
        "            if diff >= best_diff:\n",
        "                break\n",
        "            else:\n",
        "                best_diff = diff\n",
        "        left = delimiter.join(chunks[:i])\n",
        "        right = delimiter.join(chunks[i:])\n",
        "        # Возвращаем левую и правую часть оптимально разделенной строки\n",
        "        return [left, right]\n",
        "\n",
        "\n",
        "# Функция обрезает строку до максимально разрешенного числа токенов\n",
        "def truncated_string(\n",
        "    string: str, # строка\n",
        "    model: str, # модель\n",
        "    max_tokens: int, # максимальное число разрешенных токенов\n",
        "    print_warning: bool = True, # флаг вывода предупреждения\n",
        ") -> str:\n",
        "    \"\"\"Обрезка строки до максимально разрешенного числа токенов.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    encoded_string = encoding.encode(string)\n",
        "    # Обрезаем строку и декодируем обратно\n",
        "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
        "    if print_warning and len(encoded_string) > max_tokens:\n",
        "        print(f\"Предупреждение: Строка обрезана с {len(encoded_string)} токенов до {max_tokens} токенов.\")\n",
        "    # Усеченная строка\n",
        "    return truncated_string\n",
        "\n",
        "# Функция делит секции статьи на части по максимальному числу токенов\n",
        "def split_strings_from_subsection(\n",
        "    subsection: tuple[list[str], str], # секции\n",
        "    max_tokens: int = 1000, # максимальное число токенов\n",
        "    model: str = GPT_MODEL, # модель\n",
        "    max_recursion: int = 5, # максимальное число рекурсий\n",
        ") -> list[str]:\n",
        "    \"\"\"\n",
        "    Разделяет секции на список из частей секций, в каждой части не более max_tokens.\n",
        "    Каждая часть представляет собой кортеж родительских заголовков [H1, H2, ...] и текста (str).\n",
        "    \"\"\"\n",
        "    titles, text = subsection\n",
        "    string = \"\\n\\n\".join(titles + [text])\n",
        "    num_tokens_in_string = num_tokens(string)\n",
        "    # Если длина соответствует допустимой, то вернет строку\n",
        "    if num_tokens_in_string <= max_tokens:\n",
        "        return [string]\n",
        "    # если в результате рекурсия не удалось разделить строку, то просто усечем ее по числу токенов\n",
        "    elif max_recursion == 0:\n",
        "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
        "    # иначе разделим пополам и выполним рекурсию\n",
        "    else:\n",
        "        titles, text = subsection\n",
        "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]: # Пробуем использовать разделители от большего к меньшему (разрыв, абзац, точка)\n",
        "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
        "            if left == \"\" or right == \"\":\n",
        "                # если какая-либо половина пуста, повторяем попытку с более простым разделителем\n",
        "                continue\n",
        "            else:\n",
        "                # применим рекурсию на каждой половине\n",
        "                results = []\n",
        "                for half in [left, right]:\n",
        "                    half_subsection = (titles, half)\n",
        "                    half_strings = split_strings_from_subsection(\n",
        "                        half_subsection,\n",
        "                        max_tokens=max_tokens,\n",
        "                        model=model,\n",
        "                        max_recursion=max_recursion - 1, # уменьшаем максимальное число рекурсий\n",
        "                    )\n",
        "                    results.extend(half_strings)\n",
        "                return results\n",
        "    # иначе никакого разделения найдено не было, поэтому просто обрезаем строку (должно быть очень редко)\n",
        "    return [truncated_string(string, model=model, max_tokens=max_tokens)]\n"
      ],
      "metadata": {
        "id": "up9rkSUVySMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Делим секции на части\n",
        "MAX_TOKENS = 1600\n",
        "wikipedia_strings = []\n",
        "for section in wikipedia_sections:\n",
        "    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
        "\n",
        "print(f\"{len(wikipedia_sections)} секций Википедии поделены на {len(wikipedia_strings)} строк.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dM_AWecyXbh",
        "outputId": "c24aa961-8b6a-4585-b074-e8c9beeedca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5264 секций Википедии поделены на 6147 строк.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Напечатаем пример строки\n",
        "print(wikipedia_strings[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXQ1mrpUyeHV",
        "outputId": "5e56e9d9-6143-457f-ee7a-2916af6df811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Belgium at the 2022 Winter Olympics\n",
            "\n",
            "==Medalists==\n",
            "\n",
            "{{further|2022 Winter Olympics medal table|List of 2022 Winter Olympics medal winners}}\n",
            "The following Belgium competitors won medals at the games. In the discipline sections below, the medalists' names are '''bolded'''. On 19 February, [[Bart Swings]], won Belgium's first Winter Olympic Gold medal since the [[1948 Winter Olympics]].\n",
            "\n",
            "{|class=\"wikitable sortable\" style=\"font-size: 95%;\"\n",
            "!width=60px| Medal\n",
            "!width=125px| Name\n",
            "!width=125px| Sport\n",
            "!width=150px| Event\n",
            "!Date\n",
            "|-\n",
            "|{{gold medal}}||{{sortname|Bart|Swings}}||[[Speed skating at the 2022 Winter Olympics|Speed skating]]||[[Speed skating at the 2022 Winter Olympics – Men's mass start|Men's mass start]]||{{dts|19 February}}\n",
            "|-\n",
            "|{{bronze medal}}||{{sortname|Hanne|Desmet}}||[[Short track speed skating at the 2022 Winter Olympics|Short track speed skating]]||[[Short track speed skating at the 2022 Winter Olympics – Women's 1000 metres|Women's 1000 m]]||{{dts|11 February}}\n",
            "|}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизация и сохранение результата"
      ],
      "metadata": {
        "id": "XB_0hDCcN9aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда мы разделили нашу базу знаний на более короткие автономные строки, мы можем вычислять эмбединги для каждой строки."
      ],
      "metadata": {
        "id": "ngV5CmVuOBmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # Модель токенизации от OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")\n",
        "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Функция отправки chatGPT строки для ее токенизации (вычисления эмбедингов)\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "\n",
        "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n"
      ],
      "metadata": {
        "id": "G9Zg31ag2UxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не будем мучать chatGPT 6 тыс. запросами, сформируем базу данных для 10 строк. Мы всегда должны помнить о расходах при работе с chatGPT. Сформировать полноценный `csv` файл с эмбедингами для 6 тыс. строк нам обойдется чуть больше доллара."
      ],
      "metadata": {
        "id": "rW9NrBBjX2O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"text\": wikipedia_strings[:10]})\n",
        "\n",
        "df['embedding'] = df.text.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "\n",
        "SAVE_PATH = \"./winter_olympics_2022.csv\"\n",
        "# Сохранение результата\n",
        "df.to_csv(SAVE_PATH, index=False)"
      ],
      "metadata": {
        "id": "hp4psjkOPCIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поскольку в этом примере используется всего 6 тысяч строк, мы сохраним базу знаний в CSV-файле.\n",
        "\n",
        "Для больших наборов данных необходимо использовать векторную базу данных, которая будет более производительной."
      ],
      "metadata": {
        "id": "PpvdrW_vhZiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UfmUo3ujPZE6",
        "outputId": "7a11e60f-fc19-4132-fbdc-1300846f4e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Belgium at the 2022 Winter Olympics\\n\\n{{Infob...   \n",
              "1  Belgium at the 2022 Winter Olympics\\n\\n==Medal...   \n",
              "2  Belgium at the 2022 Winter Olympics\\n\\n==Compe...   \n",
              "3  Belgium at the 2022 Winter Olympics\\n\\n==Alpin...   \n",
              "4  Belgium at the 2022 Winter Olympics\\n\\n== Biat...   \n",
              "\n",
              "                                           embedding  \n",
              "0  [-0.013823332265019417, -0.02333245798945427, ...  \n",
              "1  [-0.0029811249114573, -0.017298921942710876, -...  \n",
              "2  [-0.01078924909234047, -0.0016377692809328437,...  \n",
              "3  [0.002883633365854621, -0.004151271190494299, ...  \n",
              "4  [-0.011562004685401917, 0.0025838338769972324,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-355263ad-1eb7-4132-9d3a-2246412d51d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Belgium at the 2022 Winter Olympics\\n\\n{{Infob...</td>\n",
              "      <td>[-0.013823332265019417, -0.02333245798945427, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Belgium at the 2022 Winter Olympics\\n\\n==Medal...</td>\n",
              "      <td>[-0.0029811249114573, -0.017298921942710876, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Belgium at the 2022 Winter Olympics\\n\\n==Compe...</td>\n",
              "      <td>[-0.01078924909234047, -0.0016377692809328437,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Belgium at the 2022 Winter Olympics\\n\\n==Alpin...</td>\n",
              "      <td>[0.002883633365854621, -0.004151271190494299, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Belgium at the 2022 Winter Olympics\\n\\n== Biat...</td>\n",
              "      <td>[-0.011562004685401917, 0.0025838338769972324,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-355263ad-1eb7-4132-9d3a-2246412d51d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-355263ad-1eb7-4132-9d3a-2246412d51d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-355263ad-1eb7-4132-9d3a-2246412d51d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b954f96d-8d9b-4406-8e20-01225d2f93e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b954f96d-8d9b-4406-8e20-01225d2f93e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b954f96d-8d9b-4406-8e20-01225d2f93e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь когда вы уже умеете создавать базу знаний для обучения chatGPT, пора переходить к [Домашней работе](https://colab.research.google.com/drive/13zTaGNA9cr9SjaYFzpDPp-72i8SQFqrp)"
      ],
      "metadata": {
        "id": "-zSac8X8Qk5S"
      }
    }
  ]
}