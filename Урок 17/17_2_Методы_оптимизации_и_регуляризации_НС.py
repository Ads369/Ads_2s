# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.16.4
#   kernelspec:
#     display_name: Python 3
#     name: python3
# ---

# %% [markdown] id="view-in-github" colab_type="text"
# <a href="https://colab.research.google.com/github/Ads369/Ads_2s/blob/main/17_2_%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%9D%D0%A1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# %% [markdown] id="gDthUNquMPmu"
# **Навигация по уроку**
#
# 1. [Проблема переобучения нейронных сетей](https://colab.research.google.com/drive/10jxb_tGNTenMkxuC7ksTjjUtq966mZMM#scrollTo=SOSDEbSwa-Hj)
# 2. Методы оптимизации и регуляризации НС
# 3. [Универсальный алгоритм машинного обучения](https://colab.research.google.com/drive/1hK-5MC4eApd1-tRMppY9X9RLUYeMqG4q)
# 4. [Домашняя работа](https://colab.research.google.com/drive/1e0K_XldGH5ac4Y2N7rbK56rEJx0vXu3C)

# %% [markdown] id="sd2jT0xtPeYW"
# В данной части урока мы рассмотрим проблему переобучения нейронной сети на примере набора данных IMDB с отзывами на фильмы и на его примере изучим вопросы оптимизации и регуляризации.

# %% [markdown] id="m_he5TCZQ-tg"
# ## Набор данных IMDB

# %% [markdown] id="gbNjHraNRH2A"
# Мы будем работать с набором данных IMDB. Он состоит из 50 000 отзывов к фильмам базы Internet Movie Database. Набор разбит на 25 000 обучающих и 25 000 контрольных отзывов, каждый набор на 50 % состоит из отрицательных и на 50 % из положительных отзывов.
#
# Подобно MNIST, набор данных IMDB поставляется в составе Keras. Он уже готов
# к использованию: отзывы (последовательности слов) преобразованы в последовательности целых чисел, каждое из которых определяет позицию слова в словаре.

# %% [markdown] id="At43U3Y2Q0Q2"
# ### Загрузка набора данных IMDB

# %% id="G2cHczJCQfON"
from keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)


# %% [markdown] id="jzc6x-g_nGNH"
# Аргумент `num_words=10000` означает, что в обучающих данных будет сохранено
# только 10 000 слов, наиболее часто встречающихся в обучающем наборе отзывов. Редкие слова будут отброшены.
#
# Переменные `train_data` и `test_data` — это списки отзывов, где каждый отзыв — это список индексов слов (кодированное представление последовательности слов).
# Переменные `train_labels` и `test_labels` — это списки нулей и единиц, где нули
# соответствуют отрицательным отзывам, а единицы — положительным.

# %% colab={"base_uri": "https://localhost:8080/"} id="FaeS4567ntFb" outputId="38a9743f-5a44-4664-c850-3571d04db499"
print(train_data[0])

# %% colab={"base_uri": "https://localhost:8080/"} id="TKQ6gHY-nyPg" outputId="386f8029-3f3f-431d-fa47-19015cd7637d"
print(train_labels[0])

# %% [markdown] id="CXvEumyApO-v"
# Поскольку мы ограничили себя 10 000 наиболее употребительных слов, в наборе
# отсутствуют индексы больше 10 000. Также первые 3 индекса (0, 1 и 2) зарезервированы для слов «padding» (отступ), «start of sequence» (начало
# последовательности) и «unknown» (неизвестное слово).
#
# Как мы видим `train_data[0]` содержит список индексов слов. Преобразуем его (декодируем) в реальный отзыв (последовательность слов на английском языке) для наглядности. Неизвестные слова или редко встречающиеся отметим символом `?`:

# %% colab={"base_uri": "https://localhost:8080/"} id="8ufqjzoxihMT" outputId="cf938c32-eb8c-47c5-8c23-9d4ee2ce5352"
# Получение словаря
word_index = imdb.get_word_index()
print(word_index)

# %% colab={"base_uri": "https://localhost:8080/"} id="JPKwnbD7i1Oi" outputId="ce8337d6-d255-435c-aac4-4949d6679d90"
# Инвертируем словарь, меняем местами ключ и значение
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
print(reverse_word_index)

# %% colab={"base_uri": "https://localhost:8080/"} id="CfGShveroUzf" outputId="16aa34f2-0ed1-48e8-f91e-15ec9a5b48ee"
# Декодируем с помощью словаря первый элемент обучающей выборки
decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])
print(decoded_review)

# %% [markdown] id="uPZNMXx0l6NS"
# ### Подготовка данных

# %% [markdown] id="ojB9_OcLmHd3"
# Нельзя передать списки целых чисел непосредственно в нейронную сеть. Поэтому
# мы должны преобразовать их в тензоры. Сделать это можно двумя способами:
# * Привести все списки к одинаковой длине, преобразовать их в тензоры целых
# чисел с формой и затем передать их в первый слой сети, способный обрабатывать такие целочисленные тензоры (слой Embedding, к нему мы еще вернемся).
# * Выполнить прямое кодирование списков в векторы нулей и единиц. Это может
# означать, например, преобразование последовательности [3, 5] в 10 000-мерный
# вектор, все элементы которого содержат нули, кроме элементов с индексами
# 3 и 5, которые содержат единицы. Затем их можно передать в первый слой сети типа Dense, способный обрабатывать векторизованные данные с вещественными
# числами.
# Мы пойдем по второму пути, с векторизованными данными, которые создадим
# вручную, чтобы было понятнее.
#
# Векторизовать данные будем с помощью функции `vectorize_sequences`:

# %% id="x2iApfHksR4B"
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension)) # Создаем нулевой вектор с размерностью 10000!
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1. # Записываем единицы в элемент с данным индексом
    return results

x_train = vectorize_sequences(train_data) # Векторизуем обучающие данные
x_test  = vectorize_sequences(test_data)  # Векторизуем контрольные данные

# %% [markdown] id="Zy090A0QnGoe"
# Вот как теперь выглядят образцы:

# %% colab={"base_uri": "https://localhost:8080/"} id="vl0lfhxrsRIV" outputId="df730720-5f1e-42d1-8df4-7ae8edcbc29d"
x_train[0]

# %% [markdown] id="S3HeS6yYndua"
# Нам также нужно преобразовать метки к тензору типа `float32`, что делается достаточно просто:

# %% id="n3uUKAfZsRlx"
y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')

# %% colab={"base_uri": "https://localhost:8080/"} id="MIooYzBenVGy" outputId="3bfad1d2-db70-4dc1-8a7b-70b66b17826e"
print(y_train[0])

# %% [markdown] id="MhoGz0fHn3sj"
# ### Архитектура сети

# %% [markdown] id="6NRvBCblrHlP"
# Входные данные представлены векторами, а метки — скалярами (единицами и нулями). С задачами такого вида прекрасно справляются сети, организованные как простой стек полносвязных (Dense) слоев с операцией активации relu. В качестве выходного слой логично использовать один нейрон с сигмоидной функцией активации, которая будет определять вероятность (оценку вероятности, между 0 и 1 того, что образец относится к классу «1», то есть к положительному отзыву).
# С математической точки зрения, функция relu используется для преобразования отрицательных значений в ноль, а сигмоидная функция рассредоточивает произвольные значения по интервалу [0, 1], возвращая значения, которые мы интерпретируем как вероятность.

# %% id="Xe9v4ZUIszYM"
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

# %% [markdown] id="q0S_QeEeuSwL"
# Наконец, нужно выбрать функцию потерь и оптимизатор. Так как перед нами стоит
# задача бинарной классификации и результатом работы сети является вероятность, предпочтительнее использовать функцию потерь `binary_crossentropy`. Но
# это не единственный вариант, так как можно использовать, например, `mean_squared_error`. Однако перекрестная энтропия обычно дает лучшие результаты, когда результатами работы моделей являются вероятности.
#
# Перекрестная энтропия (crossentropy) — это термин из области теории информации,
# обозначающий меру расстояния между распределениями вероятностей, или в данном случае — между фактическими данными и предсказаниями.
#
# На этом шаге мы настраиваем модель оптимизатором `adam` и функцией потерь
# `binary_crossentropy`. Обратите внимание, что мы также задали мониторинг точности (`accuracy`) во время обучения.

# %% [markdown] id="8Qh3-OHc2FpH"
# Проведем обучение модели в течение 10 эпох (выполнив 10 итераций по всем образцам x_train, y_train) пакетами по 256 образцов.

# %% colab={"base_uri": "https://localhost:8080/"} id="_FrDmt4etSBq" outputId="f49890b7-28b3-4538-9858-02dc90055a48"
EPOCHS = 10
BATCH_SIZE = 256
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)

# %% [markdown] id="BDsO1TWE2ttE"
# Обратите внимание на то, что вызов `model.fit()` возвращает объект `History`. Этот объект имеет поле `history` — это словарь с данными обо всех итерациях процесса обучения и валидации. Заглянем в него:

# %% colab={"base_uri": "https://localhost:8080/"} id="zKjzo6oWtbyB" outputId="e69b5de9-cf70-41b2-b2dc-a35ec253c543"
history_dict = history.history
history_dict.keys()

# %% [markdown] id="e3SZ0R2B3A2F"
# Словарь содержит четыре элемента — по одному на метрику, — за которыми
# осуществлялся мониторинг в процессе обучения и проверки. Имея эти данные, мы теперь можем построить графики потерь и точности на этапах обучения и проверки.
#
# **ВАЖНО**. Имейте в виду, что после каждого перезапуска процесса обучения, графики могут различаться, что обусловлено различием в случайных числах, использовавшихся для инициализации весов сети.

# %% colab={"base_uri": "https://localhost:8080/", "height": 472} id="vhv2J9AMtj1G" outputId="4189edc8-c015-42f7-97b5-548bdaceeafa"
import matplotlib.pyplot as plt
history_dict = history.history
epochs = range(1, len(history_dict['loss'])+1)
plt.plot(epochs, history_dict['loss'], 'bo', label='Потери на этапе обучения')
plt.plot(epochs, history_dict['val_loss'], 'b', label='Потери на этапе проверки')
plt.title('Потери на этапах проверки и обучения')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()
plt.show()

# %% colab={"base_uri": "https://localhost:8080/", "height": 472} id="S9klfngvvG3V" outputId="9914fab4-7b82-43ed-9489-bfc8d7d2be1b"
plt.clf() # Очистить рисунок
plt.plot(epochs, history_dict['accuracy'], 'bo', label='Точность на этапе обучения')
plt.plot(epochs, history_dict['val_accuracy'], 'b', label='Точность на этапе проверки')
plt.title('Точность на этапе проверки и обучения')
plt.xlabel('Эпохи')
plt.ylabel('Точность')
plt.legend()
plt.show()

# %% [markdown] id="iHNIspc8ot8s"
# Мы видим, что на этапе обучения потери снижаются с каждой эпохой, а точность
# растет. Именно такое поведение ожидается от оптимизации градиентным спуском: величина, которую вы пытаетесь минимизировать, должна становиться
# все меньше с каждой итерацией. Но это не относится к потерям и точности на
# этапе проверки. Они достигли пика на 2-ю эпоху. Это пример того, о чем мы предупреждали выше: модель, показывающая хорошие результаты на обучающих данных, не обязательно будет показывать такие же хорошие результаты на данных, которые не видела прежде. Выражаясь точнее, в данном случае наблюдается переобучение. После второй эпохи произошла чрезмерная оптимизация на обучающих данных, и в результате получилось представление, характерное для обучающих данных, не обобщающее данные за пределами обучающего набора.

# %% [markdown] id="Oqs58JTQ62vb"
# ## Методы оптимизации и регуляризации

# %% [markdown] id="1Ywl3KVfHZS_"
# Основной проблемой машинного обучения является противоречие между **оптимизацией** и **общностью**.
#
# **ВАЖНО**. Под оптимизацией понимается процесс настройки модели для получения максимального качества на тренировочных данных (обучение в машинном обучении), а под общностью — качество обученной модели на данных, которые она прежде не видела.
#
# > Цель игры — добиться высокого уровня общности, но вы не можете управлять общностью, вы можете только настраивать модель, опираясь на тренировочные данные.
#
# В начале обучения оптимизация и общность коррелируются: чем ниже потери на
# тренировочных данных, тем они ниже на контрольных данных. Пока это имеет место, говорят, что модель недообучена: прогресс еще возможен, сеть еще не смоделировала все релевантные шаблоны в тренировочных данных. Однако после нескольких итераций на тренировочных данных общность перестает улучшаться, проверочные метрики останавливают свой рост и затем начинают ухудшаться — наступает эффект переобучения модели. Другими словами, модель начинает обучаться шаблонам, характерным для тренировочных данных, но нехарактерным для новых данных.
#
# Лучший способ предотвратить изучение моделью специфических или нерелевантных шаблонов, имеющих место в тренировочных данных, — увеличить объем тренировочных данных. Модель, обученная на большем объеме данных, будет иметь большую общность. Если это невозможно, следующим лучшим способом является регулирование качества информации или добавление ограничений на информацию, которую модели будет позволено сохранить. Если сеть может позволить себе сохранить только небольшое количество шаблонов, процесс оптимизации заставит ее сосредоточиться на наиболее существенных из них, что увеличит шансы на достижение более высокого уровня общности.
#
# Борьба с переобучением таким способом называется регуляризацией. Рассмотрим
# некоторые распространенные приемы регуляризации и применим их на практике.
#
#

# %% [markdown] id="kVWZCTHnIIP6"
# ## Уменьшение размера сети

# %% [markdown] id="Fg-eqrrWIL0c"
# Самый простой способ предотвратить переобучение — уменьшить размер модели:
# количество изучаемых параметров в модели (определяется количеством слоев
# и количеством нейронов (размерностью) в каждом слое). В глубоком обучении количество изучаемых параметров в модели часто называют емкостью модели (model
# capacity). Очевидно, что чем большим количеством параметров обладает модель,
# тем большим объемом памяти она обладает и модель стремиться к прямому отображению тренировочных экземпляров, т.е. отображению без обобщения.
#
# Но такая модель оказалась бы практически бесполезной для классификации новых данных.
#
# **ВАЖНО**. Модели глубокого обучения, как правило, хорошо подогнаны под тренировочные данные, но главная задача — достижение общности, а не подгонка под данные.
#
# С другой стороны, если сеть имеет ограниченный объем ресурсов для запоминания,
# она не сможет получить прямое отображение. Поэтому, чтобы минимизировать
# потери, ей придется прибегнуть к изучению сжатых представлений, обладающих
# более широкими возможностями прогноза в отношении целей, — именно эти
# представления больше всего интересуют нас. В то же время модель должна иметь
# достаточное количество параметров, чтобы не возник эффект недообучения: она
# не должна испытывать недостатка в ресурсах для запоминания. Важно найти компромисс между слишком большой и недостаточной емкостью.
#
# К сожалению, нет волшебной формулы для определения правильного количества
# слоев или правильного размера каждого слоя. Вам придется оценить огромный массив разных архитектур, чтобы определить правильный размер модели для ваших данных. При этом, опираясь на проверочный набор, но не на контрольный. В общем случае процесс поиска подходящего размера модели должен начинаться с относительно небольшого количества слоев и параметров, а затем размеры слоев и их количество должны постепенно увеличиваться, пока не произойдет увеличение потерь на проверочных данных.

# %% [markdown] id="fTWIyTy7AEai"
# Давайте уменьшим нашу модель и посмотрим, что же произойдет:

# %% id="goKb9SxqN8nB" colab={"base_uri": "https://localhost:8080/", "height": 819} outputId="de16bebd-cf20-4ae0-c6dc-f979dfdaef79"
model = models.Sequential()
model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))
model.add(layers.Dense(4, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)

history_dict = history.history
epochs = range(1, len(history_dict['loss'])+1)
plt.plot(epochs, history_dict['loss'], 'bo', label='Потери на этапе обучения')
plt.plot(epochs, history_dict['val_loss'], 'b', label='Потери на этапе проверки')
plt.title('Потери на этапах проверки и обучения (уменьшенная модель)')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()
plt.show()

# %% [markdown] id="ZEr_7sYWANwA"
# Как видите, эффект переобучения уменьшенной сети возникает позже, чем исходной (после четырех эпох, а не двух), и после переобучения ее качество ухудшается
# более плавно.

# %% id="uDZ2ayrVAbNm"
# В качестве тренировки возьмите увеличенную модель и проанализируйте функцию потерь. Что изменилось?

# %% [markdown] id="AcpBhm2uAZtS"
# ### Добавление регуляризации весов

# %% [markdown] id="vOaXuRvQAzYV"
# Программисты - народ веселый и очень любят всякие принципы! Среди программистов очень популярен методологический принцип "бритвы Оккама" или "лезвия Оккама". Который гласит: "Не следует плодить новые сущности без крайней на то необходимости". Т.е. чем более простой процесс, модель, код - тем они более стабильны, предсказуемы и в них меньше "багов" (ошибок).
#
# Эта идея применима также к моделям нейронных сетей: для одних и тех же наборов тренировочных данных и архитектуры сети существует множество наборов весовых значений (моделей), объясняющих данные. Более простые модели менее склонны к переобучению, чем сложные.
#
# Простая модель в данном контексте — это модель, в которой распределение значений параметров имеет меньшую энтропию (или модель с меньшим числом параметров). То есть типичный способ смягчения проблемы переобучения заключается в уменьшении сложности сети путем ограничения значений ее весовых коэффициентов, что делает их распределение более равномерным.
#
# Этот прием называется **регуляризацией весов** и реализуется добавлением в функцию потерь сети штрафа за увеличение весов и имеет две разновидности:
# * **L1-регуляризация** — добавляемый штраф прямо пропорционален абсолютным значениям весовых коэффициентов (L1-норма весов).
# * **L2-регуляризация** — добавляемый штраф пропорционален квадратам значений весовых коэффициентов (L2-норма весов). В контексте нейронных сетей L2-регуляризация также называется сокращением весов (weight decay). Это два разных названия одного и того же явления: сокращение весов с математической точки зрения суть то же самое, что L2-регуляризация.
#
# В Keras регуляризация весов осуществляется путем передачи в слои именованных
# аргументов с экземплярами регуляризаторов весов. Рассмотрим пример добавления
# L2-регуляризации в сеть классификации отзывов о фильмах

# %% colab={"base_uri": "https://localhost:8080/", "height": 819} id="KCm4JnvoDEQR" outputId="893308d7-3938-48bb-e71a-3546a73d4c5c"
from keras import regularizers

model = models.Sequential()
model.add(layers.Dense(16, activation='relu',  kernel_regularizer=regularizers.l2(0.001), input_shape=(10000,)))
model.add(layers.Dense(16, activation='relu',  kernel_regularizer=regularizers.l2(0.001)))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)

history_dict = history.history
epochs = range(1, len(history_dict['loss'])+1)
plt.plot(epochs, history_dict['loss'], 'bo', label='Потери на этапе обучения')
plt.plot(epochs, history_dict['val_loss'], 'b', label='Потери на этапе проверки')
plt.title('Потери на этапах проверки и обучения (с регуляризацией)')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()
plt.show()

# %% [markdown] id="XlPIb96oDbpU"
# `l2(0.001)` означает, что каждый коэффициент в матрице весов слоя будет добавлять `0.001 * weight_coefficient_value` в общее значение потерь сети. Обратите внимание: так как штраф добавляется только на этапе обучения, величина потерь сети на этапе обучения будет намного выше, чем на этапе контроля. Модель с L2-регуляризацией устойчивее к переобучению, чем исходная модель, даже при том, что обе модели имеют одинаковое количество параметров.
#
# Вместо L2-регуляризации можно также использовать следующие регуляризаторы,
# входящие в состав Keras:
#
# ```python
# regularizers.l1(0.001) # L1-регуляризация
# regularizers.l1_l2(l1=0.001, l2=0.001) # Объединенная L1- и L2-регуляризация
# ```

# %% [markdown] id="wFxW4491EZUO"
# ### Прореживание

# %% [markdown] id="xHgDivQ6EfAk"
# Прореживание (dropout) — один из наиболее эффективных и распространенных
# приемов регуляризации для нейронных сетей, разработанный Джеффом Хинтоном
# (Geoff Hinton) и его студентами в Университете Торонто.
#
# Прореживание, которое применяется к слою, заключается в удалении (присваивании нуля) случайно выбираемым признакам на этапе обучения.
#
# Коэффициент прореживания — это доля обнуляемых признаков. Обычно он выбирается в диапазоне от 0,2 до 0,5. На этапе тестирования прореживание не производится, вместо этого выходные значения уровня уменьшаются на коэффициент, равный коэффициенту прореживания, чтобы компенсировать разницу в активности признаков на этапах тестирования и обучения.
#
# Рассмотрим матрицу Numpy, содержащую результат слоя, layer_output. На этапе обучения мы обнуляем случайно выбираемые значения в матрице:
#
# ```python
# # На этапе обучения обнуляется 50% признаков в выводе
# layer_output *= np.random.randint(0, high=2, size=layer_output.shape)
# ```
#

# %% [markdown] id="eGSZtaWLJfC5"
# На этапе тестирования мы уменьшаем результаты на коэффициент прореживания.
# В данном случае на коэффициент 0,5 (потому что прежде была отброшена половина
# признаков):
# ```python
# layer_output *= 0.5 # На этапе тестирования
# ```
# Обратите внимание на то, что этот процесс можно реализовать полностью на этапе
# обучения и оставить без изменения результаты, получаемые на этапе тестирования, что часто и делается на практике:
#
# ```python
# layer_output *= np.random.randint(0, high=2, size=layer_output.shape) # На этапе обучения
# layer_output /= 0.5  # происходит увеличение, а не уменьшение значений
# ```

# %% [markdown] id="yZrw2LMqHoTz"
# Этот прием может показаться странным и необоснованным.
#
# Каким образом он поможет справиться с переобучением?

# %% [markdown] id="pfimMLI8HolJ"
# По словам Хинтона, основой для этого приема, стал механизм, используемый банками для предотвращения мошенничества:
#
# *«Посещая свой банк, я заметил, что операционисты, обслуживающие меня, часто меняются. Я спросил одного из них, почему так происходит. Он сказал, что не знает, но им часто приходится переходить с места на место. Я предположил, что это делается для исключения мошеннического сговора
# клиента с сотрудником банка. Это навело меня на мысль, что удаление случайно
# выбранного подмножества нейронов из каждого примера может помочь предотвратить заговор модели с исходными данными и тем самым ослабить эффект переобучения».*
#
# Основная идея заключается в том, что введение шума в выходные значения может разбить случайно складывающиеся шаблоны, не имеющие большого значения (Хинтон называет их заговорами), которые модель начинает
# запоминать в отсутствие шума.
#
# В Keras добавить прореживание в сеть можно посредством уровня `Dropout`, который обрабатывает результаты работы слоя, стоящего непосредственно перед ним:
#
# ```python
# model.add(layers.Dropout(0.5))
# ```
#
# Давайте добавим два слоя Dropout в сеть IMDB и посмотрим, как это повлияет на
# эффект переобучения:

# %% colab={"base_uri": "https://localhost:8080/", "height": 819} id="7x2Vcn_cGC0l" outputId="f6042471-c02a-437c-c159-2ff1efe4cced"
from keras import regularizers

model = models.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1)

history_dict = history.history
epochs = range(1, len(history_dict['loss'])+1)
plt.plot(epochs, history_dict['loss'], 'bo', label='Потери на этапе обучения')
plt.plot(epochs, history_dict['val_loss'], 'b', label='Потери на этапе проверки')
plt.title('Потери на этапах проверки и обучения (с прореживанием)')
plt.xlabel('Эпохи')
plt.ylabel('Потери')
plt.legend()
plt.show()

# %% [markdown] id="bdZbdwTNJmr7"
# И снова наблюдается улучшение в сравнение с оригинальной моделью.

# %% [markdown] id="hVKmekRVGxPT"
# Таким образом, мы познакомились с наиболее распространенными способами ослабления проблемы переобучения нейронных сетей:
# * увеличить объем тренировочных данных;
# * уменьшить емкость сети;
# * добавить регуляризацию весов;
# * добавить прореживание.

# %% [markdown] id="Tg6zb7d6oc6B"
# Следующая часть урока поможет нам немного структурировать полученные знания и сформулировать для себя единый подход к обучению любой НС. [Идем дальше](https://colab.research.google.com/drive/1hK-5MC4eApd1-tRMppY9X9RLUYeMqG4q).
