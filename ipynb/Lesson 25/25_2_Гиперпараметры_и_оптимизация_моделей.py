# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.16.4
#   kernelspec:
#     display_name: Python 3
#     name: python3
# ---

# %% [markdown] id="view-in-github" colab_type="text"
# <a href="https://colab.research.google.com/github/Ads369/Ads_2s/blob/main/25_2_%D0%93%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D1%8B_%D0%B8_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# %% [markdown] id="N2mhuVZppaoD"
# **Навигация по уроку**
#
# 1. [Первое знакомство с AutoML](https://colab.research.google.com/drive/1bCWyzlp1-tcvt7TE60m4hFnRd5AWscWY)
# 2. Гиперпараметры и оптимизация моделей
# 3. [AutoML в Keras](https://colab.research.google.com/drive/1V7mfY8da0S-FbWxhQbchJM38JSJBmtoZ)
# 4. [Домашняя работа](https://colab.research.google.com/drive/1ti0hKew4nglRSYPSpfxQx19cGfVxU_K4)

# %% [markdown] id="Ykjk9JmRNs_k"
# Как вы уже, наверное, догодались в этой части урока мы поговорим про гиперпараметры, узнаем, что такое гиперпараметрический поиск, как с помощью него оптимизировать модели и какая роль во всем этом у AutoML.

# %% [markdown] id="z4LA0INxO5J2"
# ### Важность гиперпараметров

# %% [markdown] id="yxO5-67iN2IK"
# При создании моделей машинного обучения существует одна важная составляющая, которая часто остается за кадром, но имеет решающее значение для достижения высокой производительности и точности — это **гиперпараметры**.
#
# Как архитекторы строят основу для здания, так и выбор гиперпараметров определяет фундамент для моделей машинного обучения.
#
# **Гиперпараметры** — это параметры, которые настраиваются до начала процесса обучения и определяют как саму структуру модели, так и способ её обучения. Их правильный выбор может значительно повлиять на результаты обучения, тогда как неправильно подобранные значения гиперпараметров приведут к недообученным или переобученным моделям, а иногда вообще к неспособности модели обучаться (расхождение градиента).
#
# Способность модели к обобщению данных — ключевой аспект, определяющий её ценность в реальных задачах. Гиперпараметры влияют на эту способность, играя роль "регуляторов" модели. Правильно подобранные гиперпараметры помогают сбалансировать между "подгонкой" модели под обучающие данные (переобучение) и слишком обобщенным представлением, которое может упустить важные закономерности (недообучение).

# %% [markdown] id="w-HEFnOoO-3b"
# ### Отличие гиперпараметров от параметров модели

# %% [markdown] id="12SYXz5QPLY-"
# **Гиперпараметры** и **параметры** — это два ключевых аспекта, которые формируют модель машинного обучения. Они играют разные роли в процессе обучения и влияют на поведение и производительность модели.
#
# **Гиперпараметры** — это настройки модели, которые определяют её общую структуру и способ обучения. Эти параметры устанавливаются до начала процесса обучения и не изменяются в процессе обучения модели. Гиперпараметры оказывают влияние на то, как модель будет обучаться, какие признаки будут учитываться, и какие ограничения будут наложены на процесс обучения. Примерами гиперпараметров могут быть количество слоев и нейронов в нейронной сети, скорость обучения, шаг градиентного спуска, коэффициент регуляризации и т.д.
#
# **Параметры модели** - являются внутренними весами или коэффициентами, которые модель обучает в процессе обучения на основе обучающих данных. Эти параметры изменяются в процессе обучения с целью минимизации функции потерь и достижения наилучшего соответствия между прогнозами модели и реальными значениями целевой переменной. В случае нейронных сетей, параметры включают веса между нейронами в разных слоях.
#
# Различие между гиперпараметрами и параметрами модели заключается в том, что гиперпараметры задаются вручную до начала обучения и определяют характеристики всего процесса обучения, в то время как параметры модели вычисляются в процессе обучения на основе данных и оптимизируются для достижения наилучшей производительности.
#
# Понимание разницы между гиперпараметрами и параметрами модели является ключевым для правильного настройки моделей машинного обучения и достижения оптимальных результатов.

# %% [markdown] id="bYclfM0est2E"
# Каждый алгоритм машинного обучения имеет свои особенности и требует настройки определенных параметров, чтобы обеспечить оптимальное обучение и предсказания.
#
# Приведем **пример гиперпараметров для нейронных сетей:**
#
# 1. **Количество слоев и нейронов в каждом слое**. Определяет архитектуру нейронной сети и её способность обобщать данные.
#
# 2. **Скорость обучения (learning rate)**. Управляет размером шага градиентного спуска при обновлении весов нейронов.
#
# 3. **Функции активации**. Определяют, как нейроны будут "возбуждаться" при передаче сигнала.

# %% [markdown] id="1He91nNbQSXy"
# ## Гиперпараметрический поиск
#

# %% [markdown] id="e1jYaYBxwvz6"
# ### Методы гиперпараметрического поиска

# %% [markdown] id="hZTCGW8stgXS"
# Выбор подходящих гиперпараметров — это чрезвычайно важный этап в создании моделей машинного обучения. Неправильный выбор гиперпараметров может привести к неудовлетворительным результатам, долгим сессиям обучения и переобучению.
#
# Среди наиболее распространенных **стратегий и методов для эффективного гиперпараметрического поиска и оптимизации** обычно выделяют:
#
# 1. **Решетчатый поиск** (Grid Search).
# Этот метод предполагает задание наборов значений для каждого гиперпараметра, которые затем "перебираются" систематически для нахождения наилучшей комбинации. Для каждой комбинации гиперпараметров производится обучение модели и оценка её производительности на валидационных данных. Преимущество решетчатого подхода в том, что он гарантирует полный перебор всех заданных комбинаций гиперпараметров, что может помочь найти наилучшие значения. Однако это может быть очень ресурсозатратным, особенно при большом числе гиперпараметров и значений.
# 2. **Случайный поиск** (Random Search).
# Вместо того чтобы перебирать все комбинации, случайный поиск выбирает случайные наборы значений для каждого гиперпараметра. Этот метод может быть более эффективным по времени, так как он обычно требует меньше итераций, чтобы найти хорошие значения. Также случайный поиск может быть эффективнее в поиске оптимальных гиперпараметров, когда ресурсы ограничены. Однако есть вероятность упустить некоторые комбинации, которые могли бы быть лучшими.
# 3. **Байесовская оптимизация** или оптимизация с использованием байесовских методов (Bayesian Optimization). Это метод, который сочетает вероятностные модели с методами оптимизации для эффективного поиска оптимальных гиперпараметров. Он основан на идее моделирования функции оценки производительности модели и использования этой модели для выбора следующей точки для оценки. Байесовская оптимизация часто требует меньше итераций, чем решетчатый или случайный поиск, чтобы достичь лучших результатов.
# 4. **Применение алгоритмов глубокого обучения**.
# Глубокие нейронные сети могут быть использованы для оптимизации гиперпараметров. Например, можно использовать рекуррентные нейронные сети или сверточные нейронные сети для предсказания производительности модели с разными гиперпараметрами. Этот метод требует большого объема вычислительных ресурсов, но он может быть эффективным для сложных моделей.
#
#

# %% [markdown] id="BSyLk0XDwLvy"
# Выбор метода зависит от доступных ресурсов, сложности модели и поставленной задачи. Опыт и эксперименты помогут найти наилучший способ настройки гиперпараметров для конкретной задачи.

# %% [markdown] id="KJaRVO6Zw7F8"
# ### Рекомендации по гиперпараметрическому поиску

# %% [markdown] id="Ah8K25scxbYo"
# **Определение диапазонов гиперпараметров на основе предварительного анализа**

# %% [markdown] id="6F6jy7pQxCwO"
# Прежде чем начать гиперпараметрический поиск, важно провести предварительный анализ данных и задачи. Изучите характеристики ваших данных, исследуйте различные аспекты задачи, такие как количество признаков, баланс классов и тип задачи (например, классификация или регрессия). Это поможет вам определить диапазоны значений для гиперпараметров, которые имеют смысл для вашей задачи.
#
# Например, мы хотим подобрать гиперпараметры для конкретного слоя нашей полносвязной модели нейронной сети, тогда мы можем задать следующие параметры для поиска (число нейронов, функция активации и функция оптимизации):
#
# ```python
#
# # Определение сетки параметров для поиска
# param_grid = {
#     'neurons': [32, 64, 128],
#     'activation': ['relu', 'sigmoid'],
#     'optimizer': ['adam', 'rmsprop']
# }
# ```

# %% [markdown] id="QKL5YaobxDFs"
# **Выбор критерия оценки для сравнения моделей с разными гиперпараметрами**

# %% [markdown] id="P117tUqcxDbe"
# Оценка производительности моделей с разными гиперпараметрами является сложной задачей. Выбор подходящего критерия оценки зависит от задачи и данных. Для задач классификации, например, можно использовать различные метрики, а нетолько точность (accuracy). В задачах классификации успешно применяются следующие метрики: полнота (recall), прецизионная точность (precision) и F1-мера.
#
# Выбор критерия оценки также зависит от бизнес-целей задачи. Если вы сталкиваетесь с задачей детекции редких событий, то может быть важно сосредоточиться на максимизации полноты, чтобы убедиться, что вы не упускаете важные случаи.

# %% [markdown] id="LaCXBdY-0pNZ"
# **Используйте кросс-валидацию**

# %% [markdown] id="1bFdf8HI0pLk"
# Кросс-валидация — важный инструмент для оценки производительности моделей с разными гиперпараметрами. Она позволяет оценить, насколько хорошо модель "работает" на новых данных. Если вы решаете задачу с помощью классического машинного обучения (ML), то кросс-валидация для вас будет основным инструментом оценки и позволит избежать переобучения.
#

# %% [markdown] id="AOfCAzwf0pHD"
# **Оценка стабильности производительности модели**

# %% [markdown] id="GFiHxr112ZPo"
# Важно обращать внимание на стабильность производительности модели. Если производительность модели сильно изменяется при изменении небольших гиперпараметров, это может указывать на недостаточную стабильность.

# %% [markdown] id="b_sp2mlm3K3N"
# **Когда могут понадобиться эти рекомендации?**
#
# Для поиска гиперпараметров существует большое количество разнообразных библиотек и фреймворков, где можно в "полуавтоматическом режиме" производить настройки гиперпараметров. Например, вы решите воспользоваться методами библиотеки `Scikit-learn`:
#
#
# 1. Метод `GridSearchCV` позволяет провести решетчатый поиск по заданным наборам гиперпараметров. Этот метод применяет кросс-валидацию для каждой комбинации гиперпараметров и выбирает наилучшие.
# 2. Метод `RandomizedSearchCV` позволяет провести случайный поиск по заданным наборам гиперпараметров. Этот метод применяет кросс-валидацию для каждой комбинации гиперпараметров и выбирает наилучшие.
#
# Нам же более интересны автоматические методы и пора приступить к их изучению! Но знать об альтернативных методах необходимо и важно, возможно именно вам попадется задача, которая окажется AutoML не по зубам!
#

# %% [markdown] id="Gi_P_UJgQSRF"
# ### Применение методов AutoML для автоматической оптимизации гиперпараметров

# %% [markdown] id="ra-bt-T8R3tj"
# В поиске оптимальных гиперпараметров для моделей машинного обучения часто требуется значительное количество времени и ресурсов. Чтобы облегчить этот процесс и ускорить достижение лучших результатов, были разработаны методы автоматической оптимизации гиперпараметров.

# %% [markdown] id="zaG3oWcAQSNp"
# AutoML — это подход, который стремится автоматизировать различные этапы создания моделей машинного обучения, включая выбор алгоритмов, настройку гиперпараметров и даже предобработку данных. Это особенно полезно, когда у нас ограничены временные и вычислительные ресурсы, а также когда необходимо получить наилучший результат с минимальной затратой усилий.
#
# Одной из наиболее важных задач в рамках AutoML является автоматическая оптимизация гиперпараметров. Это позволяет облегчить процесс подбора оптимальных значений, освободив пользователя от необходимости вручную изменять их и проводить множество экспериментов.

# %% [markdown] id="B2G4_9-ZQSJg"
# ### Auto-sklearn: автоматический выбор алгоритма и оптимизация гиперпараметров

# %% [markdown] id="k2g5u4vkQSEX"
# `Auto-sklearn` — это библиотека, разработанная на основе `scikit-learn`, которая предоставляет автоматическую оптимизацию гиперпараметров и выбор алгоритмов. Она использует байесовскую оптимизацию для настройки гиперпараметров и автоматически выбирает лучший алгоритм для данной задачи. Основной класс задач, с которыми работает библиотека - это задачи классификации и регрессии.
#
# Прежде чем работать с библиотекой, ее необходимо установить. Если вы устанавливаете `auto-sklearn` на свой компьютер, то скорее всего вам достаточно будет воспользоваться одной командой:
#
# ```
# pip install auto-sklearn
# ```
#
# Однако, в Google Colab, это похоже на настоящий "КВЕСТ". Чтобы было понятней, мы ниже все команды установки отметили цифрами, чтобы не запутаться:
#
# 1. Удалите все уязвимые пакеты. Это те пакеты, чьи зависимости "мешают" нам для установки `auto-sklearn`.
# 2. Установите определенные версии пакетов (версии ниже, чем в колабе были ранее, так называемый downgrade) из удаленных. После установки пакетов колаб предложит перезапустить сессию. Необходимо согласиться и только после запускать следующую ячейку.
# 3. Установите более старую версию scikit-learn без учета ее зависимостей (запуск с параметром `--no-build-isolation`).
# 4. Финальная установка auto-sklearn.
#
# Гугл часто обновляет свои сервера, изменяются версии библиотек и их зависимости. Поэтому пробуйте сразу выполнять пункт 4, а вдруг сразу запустится. А если нет, то тогда проходите процедуру пошагам.

# %% colab={"base_uri": "https://localhost:8080/", "height": 931} id="P0_AR1Nb9jTR" outputId="ce30601a-e5cc-465a-93d4-dcb3562f8400"
# 1. удалите все уязвимые пакеты
# !pip uninstall -y Cython scipy pyparsing scikit_learn imbalanced-learn mlxtend yellowbrick

# 2. устанавливаем фиксированные версии пакетов
# !pip install Cython==0.29.36 scipy==1.9 pyparsing==2.4

# %% colab={"base_uri": "https://localhost:8080/"} id="3hqOWpeMG_Aj" outputId="4142a419-e50d-47d0-a610-e4e095d71c63"
# 3. установите более старую версию scikit-learn без учета ее зависимостей
# !pip install scikit-learn==0.24.2 --no-build-isolation

# %% colab={"base_uri": "https://localhost:8080/"} id="0tGCcWlKGikg" outputId="8b6b149c-ddaa-4ad7-d63e-a0c38204fac7"
# 4. финальная установка auto-sklearn
# !pip install auto-sklearn

# %% [markdown] id="rlRQKtVltNvC"
# Выполним простой пример ниже. Как вы видите, код очень простой и лаконичный. Мы взяли предустановленный датасет `digits` из библиотеки `sklearn`.

# %% colab={"base_uri": "https://localhost:8080/"} id="kzWKa9NO9etB" outputId="03373faa-07d3-46e1-ac5b-ba650c2f51f3"
import autosklearn.classification
import sklearn.model_selection
import sklearn.datasets

# Загрузка данных, предустановленный датасет digits
X, y = sklearn.datasets.load_digits(return_X_y=True) # return_X_y - нас интересуют как данные, так и метки классов

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)

# Создание объекта Auto-sklearn и выполнение оптимизации
automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=3600)  # time_left_for_this_task - ограничение времени поиска решения в секундах
automl.fit(X_train, y_train) # обучение

# Получение предсказаний на тестовой выборке
y_pred = automl.predict(X_test)

# Оценка производительности
accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# %% [markdown] id="Xdg76uX-gEC9"
# Мы видим, что точность модели соствила 99%. Это очень круто!

# %% [markdown] id="ZT7biq9eer4y"
# Получим модели, найденные с помощью auto-sklearn:

# %% colab={"base_uri": "https://localhost:8080/", "height": 896} id="ObtxhbCxbQej" outputId="1a50bc98-f60a-4b19-d79d-cccd19189232"
automl.leaderboard()

# %% [markdown] id="a8HZamvdmagF"
# На выходи мы получили "таблицу лидеров" для всех оцененных моделей. Содержит обзор всех моделей, прошедших обучение в процессе поиска, а также
# различные статистические данные об их обучении.
#
# Доступны следующие статистические данные:
#
# * **model_id** - идентификатор модели в библиотеке.
#
# * **rank** - ранг модели, основанный на ее "cost".
#
# * **ensemble_weight** - вес, присвоенный модели в ансамбле моделей.
#
# * **type** - тип используемого классификатора/регрессора.
#
# * **cost** - потери модели на валидационной выборке.
#
# * **duration** - период времени, на котором модель оптимизировалась.

# %% [markdown] id="HNs8HAYAe76m"
# Более детально изучить модели созданные с помощью auto-sklearn можно в формате JSON:

# %% colab={"base_uri": "https://localhost:8080/"} id="CM4TwcG9dAub" outputId="8a3d9156-df3c-4425-aa52-5f4e60b4ad29"
from pprint import pprint # удобная библиотека для печати с отступами (indent - число пробелов)
pprint(automl.show_models(), indent=4)

# %% [markdown] id="SytPhBGFQSAE"
# Мы знаем, что точность классификации модели составила 99%. Но мы сохранили интригу о датасете. Давайте выведем его на экран:
#
#

# %% colab={"base_uri": "https://localhost:8080/", "height": 112} id="8yTbWl50g88Z" outputId="454f9cbd-67fb-442e-d046-7bcc1e2f7c6e"
import matplotlib.pyplot as plt
# %matplotlib inline

# загрузим датасет c параметром return_X_y=False
digits = sklearn.datasets.load_digits(return_X_y=False)

_, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 3)) # настройки графика

# zip из 3-х списков делает новый список, состоящий из кортежей по 3 элемента
# zip(axes, digits.images, digits.target) -> [(axes[0], digits.images[0], digits.target[0]), ...]
for ax, image, label in zip(axes, digits.images, digits.target):
    # отключаем оси
    ax.set_axis_off()
    # выводим изображения в градиенте серого
    ax.imshow(image, cmap=plt.cm.gray_r)
    # устанавливаем заголовки для графиков
    ax.set_title("цифра: %i" % label)

# %% [markdown] id="yIdJuQJWiTG1"
# Набор данных digits состоит из изображений цифр размером 8x8 пикселей. Атрибут images набора данных хранит массивы значений в оттенках серого размером 8x8 пикселей для каждого изображения. Мы использовали эти массивы для визуализации первых 10 изображений. Атрибут target набора данных хранит цифру, которую представляет каждое изображение, и это включено в название графиков.
#
# Таким образом, мы видим, что на датасете, отдаленно напоминающим, знакомый нам MNIST (рукописные цифры), можно получить точность в 99% на валидационной (проверочной) выборке с помощью классического машинного обучения (ML), благодаря AutoML.

# %% [markdown] id="E9mEcSE0yL6t"
# В [следующей части урока](https://colab.research.google.com/drive/1V7mfY8da0S-FbWxhQbchJM38JSJBmtoZ) мы рассмотрим библиотеки AutoML для глубокого обучения (DL), разработанные специально для фреймворка Keras.
