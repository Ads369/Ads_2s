{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240730b7",
   "metadata": {
    "title": "Cell 0: Imports and Setup"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Constants\n",
    "RANDOM_SEED = 42\n",
    "NUM_CLASSES = 26\n",
    "WORD_DICT = {i: chr(65 + i) for i in range(NUM_CLASSES)}\n",
    "IMG_SIZE = 28\n",
    "IMG_VECTOR = IMG_SIZE**2\n",
    "history = None\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630a29d",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Cell 1: Load and Prepare Data"
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    dataset = np.loadtxt(file_path, delimiter=\",\")\n",
    "    x = dataset[:, 1 : IMG_VECTOR + 1].astype(np.float32)\n",
    "    y = dataset[:, 0].astype(np.int32)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "csv_path = Path(\"../assets/A_Z_Handwritten_Data.csv\")\n",
    "x_train, x_test, y_train, y_test = load_and_prepare_data(csv_path)\n",
    "\n",
    "print(f\"Train shape: {x_train.shape}\")\n",
    "print(f\"Test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91560e",
   "metadata": {
    "title": "Cell : check balance"
   },
   "outputs": [],
   "source": [
    "# for i in range(26):\n",
    "#     print(f\"Class {i} train: {np.mean(y_train[:, i])}, test: {np.mean(y_test[:, i])}\")\n",
    "# draw diagramma of class balance\n",
    "plt.plot(np.mean(y_train, axis=0), label=\"Train\")\n",
    "plt.plot(np.mean(y_test, axis=0), label=\"Test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Cell: Define and Compile Model\n",
    "def create_dense(layer_sizes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(IMG_VECTOR,)))\n",
    "\n",
    "    for s in layer_sizes:\n",
    "        model.add(layers.Dense(s, activation=\"sigmoid\"))\n",
    "\n",
    "    model.add(layers.Dense(units=NUM_CLASSES, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, batch_size=128, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        verbose=False,\n",
    "    )\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"training\", \"validation\"], loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(f\"Test loss: {loss:.3}\")\n",
    "    print(f\"Test accuracy: {accuracy:.3}\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e62205",
   "metadata": {
    "title": "Cell 3: Train Model"
   },
   "outputs": [],
   "source": [
    "# Проверка по количеству слоев\n",
    "for _layers in range(1, 5):\n",
    "    model = create_dense([32] * _layers)\n",
    "    history = evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71476425",
   "metadata": {
    "title": "MarkDown"
   },
   "outputs": [],
   "source": [
    "# Тестирование по количкству слоев показало, cебя плохо.\n",
    "# Больше 2 слоев - ухудшение качества результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4984427",
   "metadata": {
    "title": "Cell"
   },
   "outputs": [],
   "source": [
    "# Проверка по ширине слоя\n",
    "for nodes in [32, 64, 128, 256, 512, 1024, 2048]:\n",
    "    model = create_dense([nodes])\n",
    "    history = evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61dfbe",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "MarkDown"
   },
   "outputs": [],
   "source": [
    "# Тестирование по ширине слоя показало себя странно.\n",
    "# Модель явно улучшает качество результата.\n",
    "# Но график показывать высокую вероятность переобучаесаемости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f005fa8",
   "metadata": {
    "title": "Cell"
   },
   "outputs": [],
   "source": [
    "# Проверка по количкситву эпох\n",
    "for evals in range(1, 5):\n",
    "    model = create_dense([512, 256])\n",
    "    history = evaluate(model, epochs=evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c672f9",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "MarkDown"
   },
   "outputs": [],
   "source": [
    "# Тестирование по эпохам показало себя странно.\n",
    "# Модель явно улучшает качество результата.\n",
    "# Но график показывать высокую вероятность переобучаесаемости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5782df",
   "metadata": {
    "title": "Cell 5: Visualize Results"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history.history[\"accuracy\"], label=\"Train\")\n",
    "    ax1.plot(history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "    ax1.set_title(\"Model Accuracy\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history[\"loss\"], label=\"Train\")\n",
    "    ax2.plot(history.history[\"val_loss\"], label=\"Validation\")\n",
    "    ax2.set_title(\"Model Loss\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if history is not None:\n",
    "    plot_history(history)\n",
    "else:\n",
    "    print(\"No history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff15d20",
   "metadata": {
    "title": "Cell 6: Predictions and Visualization"
   },
   "outputs": [],
   "source": [
    "def visualize_prediction(model, x_test, y_test, index):\n",
    "    x = x_test[index].reshape(1, -1)\n",
    "    y_true = np.argmax(y_test[index])\n",
    "\n",
    "    prediction = model.predict(x)\n",
    "    y_pred = np.argmax(prediction)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(x.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {WORD_DICT[y_pred]}, True: {WORD_DICT[y_true]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize a random prediction\n",
    "random_index = np.random.randint(0, len(x_test))\n",
    "visualize_prediction(model, x_test, y_test, random_index)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
