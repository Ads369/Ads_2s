{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ads369/Ads_2s/blob/main/20_4_%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDMQlLZbr8ra"
   },
   "source": [
    "**Навигация по уроку**\n",
    "\n",
    "1. [Обработка текстов с помощью нейронных сетей](https://colab.research.google.com/drive/1tPZPtZsEi4rv4J_4tcOBMDgyUNQDYKCX)\n",
    "2. [Сравнение архитектур нейронных сетей для обработки текста](https://colab.research.google.com/drive/1KEFUgyBcqGaXGZEU-7MHENn5RH_AIvfH)\n",
    "3. [Предварительно обученные векторные представления](https://colab.research.google.com/drive/1g_dX1XpRY--X6EjFflCC0717p9_9Y1SP)\n",
    "4. Домашняя работа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sR5KZ9SVhfOY",
    "lines_to_next_cell": 2
   },
   "source": [
    "В домашней работе необходимо выполнить следующее задание:\n",
    "\n",
    "1. Подготовьте датасет с [писателями Русской литературы](https://storage.yandexcloud.net/academy.ai/russian_literature.zip) для обучения модели `Embedding` по аналогии с уроком [20.2](https://colab.research.google.com/drive/1KEFUgyBcqGaXGZEU-7MHENn5RH_AIvfH)\n",
    "2. Подгрузите веса Наташи как в уроке [20.3](https://colab.research.google.com/drive/1g_dX1XpRY--X6EjFflCC0717p9_9Y1SP) для эмбендинга.\n",
    "3. Заморозьте слой эмбединга.\n",
    "4. Выберите любых 5 писателей и обучите модель на них, не забудьте про балансировку (предварительно выделите 10% датасета на проверочную выборку и 10% на тестовую). Выбирайте писателей с большими объемами текстов, что даст большее число примеров для обучения.\n",
    "5. Добейтесь средней точности более 70% на тестовых образцах. Получите 3 балла.\n",
    "6. Если сможете добиться точности более 85% получите 4 балла.\n",
    "7. Хотите 5 баллов независимо от точности? Изучите самостоятельно и примените токенизатор [Razdel](https://github.com/natasha/razdel#usage) для данной задачи, вместо встроенного токенизатора для Keras.\n",
    "\n",
    "**Подсказка**. Так как проверка задания проводиться по средней точности на тестовых образцах (вычисляем по диагонали матрицы ошибок), то для улучшения данного показателя используйте колбэк функцию `keras.callbacks.ModelCheckpoint` из урока [19.2](https://colab.research.google.com/drive/1x2qd4MvG3ODgNrE2uqxRAZB70dGgdGft) для сохранения лучшей эпохи.\n",
    "\n",
    "**Подсказка 2**. Часто при работе с текстовыми данными вы можете заметить, что при использовании параметра `validation_split`, в методе `fit()`, точность на проверочной выборке ведет себя странно. В этом случае выделите проверочную выборку самостоятельно и используйте ее с помощью параметра `validation_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074988d",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    SpatialDropout1D,\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from navec import Navec\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999b94b",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 1. Загрузка базы писателей Русской литературы\n",
    "\n",
    "data_path = keras.utils.get_file(\n",
    "    \"russian_literature.zip\",\n",
    "    \"https://storage.yandexcloud.net/academy.ai/russian_literature.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc91f0d",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
    "!pip install navec\n",
    "%matplotlib inline\n",
    "!unzip -qo \"{data_path}\" -d ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6f730",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "navec = Navec.load(\"navec_hudlit_v1_12B_500K_300d_100q.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59666f02",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 3. Формирование датасета\n",
    "CLASS_LIST = [\"Dostoevsky\", \"Tolstoy\", \"Turgenev\", \"Chekhov\", \"Lermontov\", \"Pushkin\"]\n",
    "\n",
    "# Загрузка необходимых библиотек\n",
    "\n",
    "all_texts = {}  # Собираем в словарь весь датасет\n",
    "\n",
    "for author in CLASS_LIST:\n",
    "    # Инициализируем пустой строкой новый ключ словаря\n",
    "    all_texts[author] = \"\"\n",
    "    for path in glob.glob(\"./dataset/prose/{}/*.txt\".format(author)) + glob.glob(\n",
    "        \"./dataset/poems/{}/*.txt\".format(author)\n",
    "    ):\n",
    "        with open(f\"{path}\", \"r\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        all_texts[author] += \" \" + text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc1e63",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 4. Токенизация\n",
    "\n",
    "embedding_dim = 300  # размерность векторов эмбединга (300d в имени эмбединга)\n",
    "max_words = 10000  # Количество слов, рассматриваемых как признаки\n",
    "\n",
    "# Используется встроенный в Keras токенизатор для разбиения текста и построения частотного словаря\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=max_words,\n",
    "    filters='!\"#$%&()*+,-–—./…:;<=>?@[\\\\]^_`{|}~«»\\t\\n\\xa0\\ufeff',\n",
    "    lower=True,\n",
    "    split=\" \",\n",
    "    char_level=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Построение частотного словаря по текстам\n",
    "tokenizer.fit_on_texts(all_texts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dc453",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 5. Преобразование текста в последовательность\n",
    "\n",
    "# Преобразуем текст в последовательности:\n",
    "seq_train = tokenizer.texts_to_sequences(all_texts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b690a",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 6. Балансировка датасета\n",
    "seq_train_balance = [seq_train[cls][:40000] for cls in range(len(CLASS_LIST))]\n",
    "\n",
    "# используем генератор цикла для получения длины текстов по каждому автору\n",
    "total = sum(len(i) for i in seq_train_balance)\n",
    "print(f\"Датасет состоит из {total} слов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf17b6e",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "print(\"Общая выборка по писателям (по словам):\")\n",
    "mean_list = np.array([])\n",
    "for author in CLASS_LIST:\n",
    "    cls = CLASS_LIST.index(author)\n",
    "    print(\n",
    "        f\"{author} - {len(seq_train_balance[cls])} слов, доля в общей базе: {len(seq_train_balance[cls])/total*100 :.2f}%\"\n",
    "    )\n",
    "    mean_list = np.append(mean_list, len(seq_train_balance[cls]))\n",
    "\n",
    "print(\"Среднее значение слов: \", np.round(mean_list.mean()))\n",
    "print(\"Медианное значение слов: \", np.median(mean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37059f5d",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.pie(\n",
    "    [\n",
    "        len(i) for i in seq_train_balance\n",
    "    ],  # формируем список значений как длина символов текста каждого автора\n",
    "    labels=CLASS_LIST,  # список меток\n",
    "    pctdistance=1.2,  # дистанция размещения % (1 - граница окружности)\n",
    "    labeldistance=1.4,  # размещение меток (1 - граница окружности)\n",
    "    autopct=\"%1.2f%%\",  # формат для % (2 знака после запятой)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Шаг 7. Нарезка примеров из текста методом скользящего окна\n",
    "WIN_SIZE = 1000  # Ширина окна в токенах\n",
    "WIN_STEP = 100  # Шаг окна в токенах\n",
    "\n",
    "\n",
    "# Функция разбиения последовательности на отрезки скользящим окном\n",
    "# Последовательность разбивается на части до последнего полного окна\n",
    "# Параметры:\n",
    "# sequence - последовательность токенов\n",
    "# win_size - размер окна\n",
    "# step - шаг окна\n",
    "def seq_split(sequence, win_size, step):\n",
    "    # Делим строку на отрезки с помощью генератора цикла\n",
    "    return [\n",
    "        sequence[i : i + win_size] for i in range(0, len(sequence) - win_size + 1, step)\n",
    "    ]\n",
    "\n",
    "\n",
    "def seq_vectorize(\n",
    "    seq_list,  # Последовательность\n",
    "    test_split,  # Доля на тестовую сборку\n",
    "    class_list,  # Список классов\n",
    "    win_size,  # Ширина скользящего окна\n",
    "    step,  # Шаг скользящего окна\n",
    "):\n",
    "    # Списки для результирующих данных\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "    # Пробежимся по всем классам:\n",
    "    for class_item in class_list:\n",
    "        # Получим индекс класса\n",
    "        cls = class_list.index(class_item)\n",
    "\n",
    "        # Пороговое значение индекса для разбивки на тестовую и обучающую выборки\n",
    "        gate_split = int(len(seq_list[cls]) * (1 - test_split))\n",
    "\n",
    "        # Разбиваем последовательность токенов класса на отрезки\n",
    "        vectors_train = seq_split(\n",
    "            seq_list[cls][:gate_split], win_size, step\n",
    "        )  # последовательность до порога попадет в обучающую выборку\n",
    "        vectors_test = seq_split(\n",
    "            seq_list[cls][gate_split:], win_size, step\n",
    "        )  # последовательность после порога попадет в тестовую выборку\n",
    "\n",
    "        # Добавляем отрезки в выборку\n",
    "        x_train += vectors_train\n",
    "        x_test += vectors_test\n",
    "\n",
    "        # Для всех отрезков класса добавляем метки класса в виде one-hot-encoding\n",
    "        # Каждую метку берем len(vectors) раз, так она одинакова для всех выборок одного класса\n",
    "        y_train += [keras.utils.to_categorical(cls, len(class_list))] * len(\n",
    "            vectors_train\n",
    "        )\n",
    "        y_test += [keras.utils.to_categorical(cls, len(class_list))] * len(vectors_test)\n",
    "\n",
    "    # Возвращаем результатов как numpy-массивов\n",
    "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = seq_vectorize(\n",
    "    seq_train_balance, 0.1, CLASS_LIST, WIN_SIZE, WIN_STEP\n",
    ")\n",
    "\n",
    "print(f\"Форма входных данных для обучающей выборки: {x_train.shape}\")\n",
    "print(f\"Форма выходных данных (меток) для обучающей выборки: {y_train.shape}\")\n",
    "print(f\"Форма входных данных для тестовой выборки: {x_test.shape}\")\n",
    "print(f\"Форма выходных данных (меток) для тестовой выборки: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104a5ef",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "# Шаг 8. Определим вспомогательные функции\n",
    "# Вывод графиков точности и ошибки\n",
    "def show_plot(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "    fig.suptitle(\"График процесса обучения модели\")\n",
    "    ax1.plot(history.history[\"accuracy\"], label=\"График точности на обучающей выборке\")\n",
    "    ax1.plot(\n",
    "        history.history[\"val_accuracy\"], label=\"График точности на проверочной выборке\"\n",
    "    )\n",
    "    ax1.xaxis.get_major_locator().set_params(\n",
    "        integer=True\n",
    "    )  # На оси х показываем целые числа\n",
    "    ax1.set_xlabel(\"Эпоха обучения\")\n",
    "    ax1.set_ylabel(\"График точности\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history[\"loss\"], label=\"Ошибка на обучающей выборке\")\n",
    "    ax2.plot(history.history[\"val_loss\"], label=\"Ошибка на проверочной выборке\")\n",
    "    ax2.xaxis.get_major_locator().set_params(\n",
    "        integer=True\n",
    "    )  # На оси х показываем целые числа\n",
    "    ax2.set_xlabel(\"Эпоха обучения\")\n",
    "    ax2.set_ylabel(\"Ошибка\")\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Функция вывода предсказанных значений\n",
    "def show_confusion_matrix(y_true, y_pred, class_labels):\n",
    "    # Матрица ошибок\n",
    "    cm = confusion_matrix(\n",
    "        np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1), normalize=\"true\"\n",
    "    )\n",
    "    # Округление значений матрицы ошибок\n",
    "    cm = np.around(cm, 3)\n",
    "\n",
    "    # Отрисовка матрицы ошибок\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_title(\"Матрица ошибок\", fontsize=18)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    disp.plot(ax=ax)\n",
    "    plt.gca().images[-1].colorbar.remove()  # Убираем ненужную цветовую шкалу\n",
    "    plt.xlabel(\"Предсказанные классы\", fontsize=16)\n",
    "    plt.ylabel(\"Верные классы\", fontsize=16)\n",
    "    fig.autofmt_xdate(rotation=45)  # Наклон меток горизонтальной оси\n",
    "    plt.show()\n",
    "\n",
    "    # Средняя точность распознавания определяется как среднее диагональных элементов матрицы ошибок\n",
    "    print(\n",
    "        \"\\nСредняя точность распознавания: {:3.0f}%\".format(\n",
    "            100.0 * cm.diagonal().mean()\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Архитектура сети\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=WIN_SIZE))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(40, activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(CLASS_LIST), activation=\"softmax\"))\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "embeddings_index = navec\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1b689",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "### Обучение модели\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.1)\n",
    "model.save_weights(\"pre_trained_model.h5\")\n",
    "\n",
    "show_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c1d2a",
   "metadata": {
    "title": "cell"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "show_confusion_matrix(y_test, y_pred, CLASS_LIST)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
